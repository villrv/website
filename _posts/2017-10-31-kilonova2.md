---
layout: post
title:  gw170817
date: 2017-10-31 09:56:00-0400
description: a collection of kilonova data
categories: research
tags: astronomy, research
giscus_comments: false
related_posts: false
related_publications: villar2017combined
---



Over the last two weeks, I have been working hard on a short project to (1) aggregate and clean all available UV, optical and NIR photmetry data on the recent kilonova event and (2) fit this massive dataset to some analytical models to provide the tightest constraints on the kilonova explosion parameters. 

## Background Information

On August 17, 2017, Advanced LIGO and Virgo detected a gravitational wave from a binary neutron star merger. Many teams around the globe followed this event using both ground- and space-based telescopes. Finally, on October 16th, the event was officially announced and an unbelievable number of papers flooded the [arXiv](https://lco.global/~iarcavi/kilonovae.html). 

Immediately following this announcement, we began collecting data from the various observing groups and dumping them into the newly-created [Open Kilonova Catalog](https://kilonova.space/).

## So Much Data

There was seriously a *ton* of data collected for this event. There were about 700 photometric observations (reported) over the span of about a month -- or just over 20 observations each night! These observations also provided nearly complete color coverage of the event on any given night. Compared to supernovae, this event is probably in the top 50 of most observational points, but the well-sampled supernovae are typically observed for over 1000 days after the inital explosions. In other words, the density of observations is ntoably lower. This event is really in a leagure of its own, and it really speaks to the community effort in the observational follow-up. (Also, I don't talk about spectroscopy in the paper, but that dataset is also huge!! Right now, there are 45 spectra available on the OKC ranging from about half a day to about 10 days post-merger.)

Combining the data involved a lot of (careful work), which is honestly not very interesting ;) But I do want to mention that a lot of the work load was alleviated by our use of the code MOSFiT which automatically connects to a filter system maintained by the Spanish Virtual Observatory (link). So as long as we were able to correctly take each photometric point with its filter, instrument and telescope, the SVO and MOSFiT could take care of proper transmission functions for each data point. This saved us from many headaches.

I think it's also worth pointing out




{% if page.comments %}
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://ashleyvillar-com.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
{% endif %}

