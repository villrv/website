<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://ashleyvillar.com/al-folio/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ashleyvillar.com/al-folio/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-11T22:39:15+00:00</updated><id>https://ashleyvillar.com/al-folio/feed.xml</id><title type="html">blank</title><subtitle>Blog </subtitle><entry><title type="html">looking for needles in the haystack</title><link href="https://ashleyvillar.com/al-folio/blog/2021/anom/" rel="alternate" type="text/html" title="looking for needles in the haystack"/><published>2021-04-02T13:56:00+00:00</published><updated>2021-04-02T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2021/anom</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2021/anom/"><![CDATA[<p>In this post I will summarize the work presented at <a href="https://arxiv.org/abs/2010.11194">NeurIPS</a> (for ML-people) and submitted to <a href="https://arxiv.org/abs/2103.12102">AAS Journals</a> (for astro-people). We present a new algorithm to search for anomalous events in live LSST supernova-like time series.</p> <p>Why do we care about looking for “weirdos” with the Vera C. Rubin Observatory? LSST will observe roughly one million extragalactic transients <em>annually</em>; however, our spectroscopic and multiwavelength resrouces are in short supply! Realistically, we will only be able to conduct in-depth, active studies on 1 in 10,000 events discovered by the Rubin Observatory! We need to view each event with a critical eye, and be open to the possiblity of discovering new astrophysics. With this in mind, we developed this algorithm to search for interesting looking transients without any explicit knowledge of the undelrying physics.</p> <p>For this work, we use the (incredible!) <a href="https://plasticc.org/">PLAsTiCC</a> dataset, which is a massive simulation of galactic and extragalactic transients as they would appear in the Vera C. Rubin Observatory datastream. The simulation aims to capture the transient populations as they would appear in in 3 years of LSST data – meaning that some transients will be much more rare than others. Furthmore, the simulation is completely tagged with the physics used to generate every single event. We use this dataset to label majority (normal looking SNe) and minority classes, but we do not use these labels to build out algorithm.</p> <p>The algorithm is summarized in the figure below. In short: we figure out a data-driven model for a generic supernova; we fit all the supernovae to this model; finally, we look for weirdos based on the model parameters. The specific “model” is a variational recurrent autoencoder, an increasingly popular deep probabalistic model. The autoencoder learns a representation of the light curves by summarizing them into a small (size 10) vector. We don’t need to tell the autoencoder what type of supernova is being encoded – it learns a generic model for all the SNe.</p> <p>FIGURE</p> <p>Then, we pass each of these encoding vectors through an <em>isolation forest</em>. This technique works by attempting to isolate each event through a series of binary tree decisions. The idea is that if an event is easily isolated from the others, it is probably an anomaly. Each event received an “anomaly score”, inverses related to how many decision trees it takes to isolate the event. We also estimate the uncertainty on this score by simulating several instances of the light curves, varying flux and redshift, and running it through the same isolation forest. It is especially important to note that we are able to assign an anomaly score which actively updates as the light curve is observed!</p> <p>After running every light curve through the isolation forest, we ….</p>]]></content><author><name></name></author><category term="research"/><category term="astronomy,"/><category term="research"/><summary type="html"><![CDATA[a new anomaly detection method for LSST]]></summary></entry><entry><title type="html">a post with twitter</title><link href="https://ashleyvillar.com/al-folio/blog/2020/twitter/" rel="alternate" type="text/html" title="a post with twitter"/><published>2020-09-28T15:12:00+00:00</published><updated>2020-09-28T15:12:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2020/twitter</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2020/twitter/"><![CDATA[<p>A sample blog page that demonstrates the inclusion of Tweets/Timelines/etc.</p> <h1 id="tweet">Tweet</h1> <p>An example of displaying a tweet:</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <h1 id="timeline">Timeline</h1> <p>An example of pulling from a timeline:</p> <div class="jekyll-twitter-plugin"><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <h1 id="additional-details">Additional Details</h1> <p>For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="external-services"/><category term="formatting"/><summary type="html"><![CDATA[an example of a blog post with twitter]]></summary></entry><entry><title type="html">SuperRAENN–a new SN classifier</title><link href="https://ashleyvillar.com/al-folio/blog/2020/raenn/" rel="alternate" type="text/html" title="SuperRAENN–a new SN classifier"/><published>2020-08-13T13:56:00+00:00</published><updated>2020-08-13T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2020/raenn</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2020/raenn/"><![CDATA[<p>After a year of work, I am so happy to announce my new <a href="https://arxiv.org/abs/2008.04921">paper</a> titled, <em>SuperRAENN: A Semi-supervised Supernova Photometric Classification Pipeline Trained on Pan-STARRS1 Medium Deep Survey Supernovae</em>. This paper appears with a companion <a href="https://arxiv.org/abs/2008.04912">paper</a> led by Griffin Hosseinzadeh titled, <em>Photometric Classfication of 2315 Pan-STARRS1 Supernovae with Superphot</em>. Both of these papers build off work discussed in a previous <a href="http://ashleyvillar.com/journal/2019/06/01/sne-ml-lsst/">blog post</a>.</p> <p>This paper presents a large set of supernova-like light curves from the Pan-STARRS1 Medium Deep Survey (PS1 MDS). These were originally studied in <a href="https://ui.adsabs.harvard.edu/abs/2018ApJ...857...51J/abstract">D. Jones et al. (2018)</a>. PS1 MDS ran from 2010-2014 over 70-square degrees in griz filters. PS1 MDS is kind of like a “mili”-LSST, in that it has very similar survey properties but 1/1000th of the discovery power.</p> <p><img src="/images/aug2020/superraenn_redshift.png" alt="sample slsn light curves"/></p> <p>Of the approximately 5,000 SN-like transients we present, about 560 have spectroscopic classification. In other words, someone took a spectrum of the supernova and was able to match it to a known SN type. The Harvard team (before I joined!) led a large effort to target the host galaxies of these SN-like transients. After significant validation, we confidently present the redshift measurements of approximately 2,300 transients.</p> <p>In addition to a data release, we present a new photometric classifier for SNe, which I have named SuperRAENN. “RAENN” stands for <em>recurrent autoencoder neural network</em>. SuperRAENN uses a semi-supervised approach to classify transients.</p> <p><img src="/images/aug2020/superraenn_arch.png" alt="sample slsn light curves"/></p> <p>First, we train a novel neural network architure on unlabeled SNe. Very briefly, our neural network reads in light curves one data point at a time (in griz filters). We “encode” the light curve into just a few numbers – similar to fitting a physical model to a light curve! What is cool about our neural network determines the model from the data. After encoding the light curve, the neural network then makes this “model” into a callable function by appending time values to the encoded light curve. Through this method, we are actually able to interpolate/extrapolate light curves using our model (see below). We actually don’t really use this interpolation/extrapolation in our paper, but we plan to use it in future work using live streaming data. SuperRAENN is open source and available on <a href="https://github.com/villrv/SuperRAENN">GitHub</a>! (It’s also my first pip installable package, which was a ton of fun. I greatly benefited from this <a href="https://nsls-ii.github.io/scientific-python-cookiecutter/">tutorial</a> which Griffin sent me!)</p> <p><img src="/images/aug2020/superraenn_extra.png" alt="sample slsn light curves"/></p> <p>Next, we move on to our “supervised” step, in which we use the spectroscopically labeled SN data to train a random forest to predict the SN classes. We use hand-selected features (like peak luminosity and duration) in addition to our RAENN features in order to achieve the highest confidence classifications. We use this step to classify the remaining 1,800 SNe with redshift measurements.</p> <p>We do quite a few tests to see how reliable our classifications are. I think a nice summary is simply comparing our sample to the ZTF Bright Transient Survey sample, shown below. In short, we clearly have some small biases in our classifier, but we actually seem to understand these biases. If we correct for them, we seem to be in good agreement with the ZTF results.</p> <p><img src="/images/aug2020/superraenn_breakdown.png" alt="sample slsn light curves"/></p> <p>I think a really fun personal aspect of this paper is how many times I found myself writing “which will be explored in future work”. This paper presents many new ideas, but there are still so many questions left to be answered! I’m really excited to keep pushing on how we can use machine learning and data driven methods to push time domain astrophysics forward!</p> <p>On another personal note, this is the last chapter of my thesis! I recently moved to NYC to start a postdoc at Columbia (primary) and the Flatiron Institute. So excited to spend this year meeting new collaborators!</p>]]></content><author><name></name></author><category term="research"/><category term="astronomy,"/><category term="research"/><summary type="html"><![CDATA[After a year of work, I am so happy to announce my new paper titled, SuperRAENN: A Semi-supervised Supernova Photometric Classification Pipeline Trained on Pan-STARRS1 Medium Deep Survey Supernovae. This paper appears with a companion paper led by Griffin Hosseinzadeh titled, Photometric Classfication of 2315 Pan-STARRS1 Supernovae with Superphot. Both of these papers build off work discussed in a previous blog post.]]></summary></entry><entry><title type="html">SNIF out supernova fits</title><link href="https://ashleyvillar.com/al-folio/blog/2019/snif/" rel="alternate" type="text/html" title="SNIF out supernova fits"/><published>2019-09-30T13:56:00+00:00</published><updated>2019-09-30T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2019/snif</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2019/snif/"><![CDATA[<p>Hi all! I am writing up a short description of a new web application which was created by two wonderful high school students, Leilani and Sophie, who I’ve been working with for the past year!</p> <p>The SuperNova Interactive Fitter (<a href="snif.space">SNIF</a>) is an application built on Python (bokeh) and Javascript to allow users to interactively fit supernovae from the <a href="sne.space">Open Supernova Catalog</a>. We have three available engines: radioactive decay of 56Ni, magnetar spin-down and circumstellar material interaction. You can read the <a href="http://snif.space/tutorial.html">tutorial</a> for more information on how to actually use the app! Our hope is that the app is simple enough that it can be incorporated into undergraduate classroom activities in addition to being a useful research tool!</p> <table> <tbody> <tr> <td>I want to highlight that this application is due to the hard work of two Cambridge Ringe and Latin high school (a pubic school in Cambridge) students, Leilani and Sophie. They worked with me for a <em>year</em> through the Science Research Mentoring Program (SRMP) at the Center for Astrophysics</td> <td>Harvard &amp; Smithsonian. SRMP program founded and directed by Dr. Or Graur and is funded by and NSF award, the City of Cambridge, the John G. Wolbach Library, Cambridge Rotary, and generous individuals. These young researchers had to learn how to code in Python and Javascript, the physics of supernova light curves, and how to build a website. I’m excited to say that in addition to a web application, their hard work resulted in a <a href="https://iopscience.iop.org/article/10.3847/2515-5172/ab459b/meta">AAS Research Note</a>.</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="project"/><category term="astronomy,"/><category term="project"/><summary type="html"><![CDATA[Hi all! I am writing up a short description of a new web application which was created by two wonderful high school students, Leilani and Sophie, who I’ve been working with for the past year!]]></summary></entry><entry><title type="html">PS1-MDS SNe Classification</title><link href="https://ashleyvillar.com/al-folio/blog/2019/sne-ml-lsst/" rel="alternate" type="text/html" title="PS1-MDS SNe Classification"/><published>2019-05-27T13:56:00+00:00</published><updated>2019-05-27T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2019/sne-ml-lsst</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2019/sne-ml-lsst/"><![CDATA[<p>Today I’m going to write about a <a href="https://iopscience.iop.org/article/10.3847/1538-4357/ab418c/meta">new paper</a> we recently submitted to the Astrophysical Journal. We present a machine learning pipeline trained using a set of spectroscopically identified supernovae found within Pan-STARRS Medium Deep Survey.</p> <p><img src="/images/jun2019/sne_all.png" alt="sample slsn light curves"/></p> <p>We currently discover around 10,000 supernovae per year. I illustrate this in the plot above, which uses the latest supernova (SNe) count from <a href="sne.space">sne.space</a>, to show number of SNe as a function of discovery year (on a logarithmic scale!). I’ve highlighted several wide-field surveys which have dominated the discovers in the past few years. Wide-field surveys (as opposed to galaxy-targeted surveys) like Pan-STARRS and ZTF have changed the game for discovering new extragalactic transients!</p> <p>However, in several years, the Large Synoptic Survey Telescope (LSST) will come online and is expected to find nearly <em>one million</em> extragalactic transients, increasing our annual discovery rate by two orders of magnitude. This is a shift larger than anything we’ve seen in the past, opening a new era of data-driven time-domain astronomy!</p> <p>I like to think of this new era of as looking for “needles” in a haystack of events. Of the 1 million supernovae per year, and maybe tens of thousands of these will get spectroscopic classifications. Of these, maybe only 100 “interesting” needles will have multi-wavelength studies and receive the person-hours necessary to study them in real time.</p> <p>Searching for needles is an important problem, but I actually want to talk about the <em>haystack</em> in this blog post – the millions of light curves without followup and maybe without spectroscopic classification. Our new paper specifically addresses the question: given a redshift and “complete” optical light curve, can we classify the light curves of supernovae as their spectroscopic class?</p> <p>To answer this question, we conducted a study using the Panstarrs Medium deep survey which ran from 2010-2014 over 70-square degrees. Previous <a href="https://iopscience.iop.org/article/10.3847/1538-4357/aa767b/meta">work</a> by David Jones identified 5200 supernova-like transients in the survey, and followup efforts have allowed us to measure the host redshifts to 3100 objects. 518 objects had “high-confidence’ spectroscopic classification which we can use as SN “true labels” to train a classifier on the photometric light curves. So we want to train a machine learning algorithm to classify the 518 griz light curves into 5 supernova types: Types Ia, IIn, IIp, Ibc and superluminous. We don’t actually publish the light curves in this work – but we hope to do that soon!</p> <p>We need to extract light curve features from our dataset to train our machine learning algorithm. In this case, we developed a new analytical model which better accounts for the plateau shape of Type IIP SNe while still being able to nicely fit other classes with smooth unimodal shapes. In the image below, I’m comparing our model to other similar models from Bazin and Karpenka. To be totally fair, however, we can’t actually reproduce the 2nd bump that you often see in the redder bands of Type Ia SNe. This feature instead shows up as a plateau in our model.</p> <p><img src="/images/jun2019/f1.png" alt="sample fits to our model"/></p> <p>We fit each of the 518 LCs with a MCMC, using an iterative algorithm to tie all filters together. Here I am showing example fits, and you can see the more poorly-sample LCs, like the SLSN, have broader posteriors. This is important, because we can actually use the breadth of these fits to quantify the uncertainty of our classifier.</p> <p><img src="/images/jun2019/f3.png" alt="example fits"/></p> <p>We test a number of feature extraction techniques, data augmentation techniques, and classifiers. We find that PCA decomposition on our LCs along with a random forest classifier leads to best results. Below I show our our final confusion matrix, which tells you how well your photometric (machine-learned) labels match your spectroscopic labels.</p> <p><img src="/images/jun2019/f2.png" alt="confusion matrix"/></p> <p>It turns out that we do pretty well! If compare several metrics to models which are (1) trained on simulated data or (2) trained to just do Ia-vs-nonIa classification, we do comparable in both cases.</p> <p>We’re excited to expand on this project by fitting and classifying the remaining ~3000 SNe-like light curves. This summer, an REU student will be working on this project while we simultaneous create a totally independent way of doing this classification using neural networks!</p>]]></content><author><name></name></author><category term="research"/><category term="astronomy,"/><category term="research"/><summary type="html"><![CDATA[classification of ~3,000 supernovae]]></summary></entry><entry><title type="html">SLSNe in LSST</title><link href="https://ashleyvillar.com/al-folio/blog/2018/slsne-lsst/" rel="alternate" type="text/html" title="SLSNe in LSST"/><published>2018-09-21T13:56:00+00:00</published><updated>2018-09-21T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2018/slsne-lsst</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2018/slsne-lsst/"><![CDATA[<p>We recently submitted a <a href="https://arxiv.org/abs/1805.08192">new paper</a> to the Astrophysical Journal which presents detailed simualtions of Type I superluminous supernovae obseved with the upcoming Large Synoptic Survey Telescope.</p> <p>We fit the light curves of 58 known SLSNe at z~0.1-1.6, using an analytical magnetar spin-down model implemented in MOSFiT. We then use the posterior distributions of the magnetar and ejecta parameters to generate thousands of synthetic SLSN light curves, and we inject those into the OpSim to generate realistic ugrizy light curves.</p> <p><img src="/images/slsn_lsst/f1.png" alt="sample slsn light curves"/> <em>Sample SLSN light curves</em></p> <p>We define simple, measurable metrics to quantify the detectability and utility of the light curve, and to measure the efficiency of LSST in returning SLSN light curves satisfying these metrics.</p> <p><img src="/images/slsn_lsst/f2.png" alt="efficienies as function of redshift"/> <em>Recovery efficiency as a function of redshift</em></p> <p>We combine the metric efficiencies with the volumetric rate of SLSNe to estimate the overall discovery rate of LSST, and we find that ~10^4 SLSNe per year with &gt;10 data points will be discovered in the WFD survey at z&lt;3.0, while only ~15 SLSNe per year will be discovered in each DDF at z&lt;4.0.</p> <p><img src="/images/slsn_lsst/f3.png" alt="number of discovered slsne as function of redshift"/> <em>Number of discovered SLSNe as a function of redshift</em></p> <p>To evaluate the information content in the LSST data, we refit representative output light curves with the same model that was used to generate them.</p> <p><img src="/images/slsn_lsst/f4.png" alt="refitted light curves"/> <em>Sample SLSN light curves with best-fit magnetar models</em></p> <p>We correlate our ability to recover magnetar and ejecta parameters with the simple light curve metrics to evaluate the most important metrics. We find that we can recover physical parameters to within 30% of their true values from ~18% of WFD light curves. Light curves with measurements of both the rise and decline in gri-bands, and those with at least fifty observations in all bands combined, are most information rich, with ~30% of these light curves having recoverable physical parameters to ~30% accuracy. WFD survey strategies which increase cadence in these bands and minimize seasonal gaps will maximize the number of scientifically useful SLSN light curves. Finally, although the DDFs will provide more densely sampled light curves, we expect only ~50 SLSNe with recoverable parameters in each field in the decade-long survey.</p> <p><img src="/images/slsn_lsst/f5.png" alt="lc recovery rate as function of number of points"/> <em>Recovered parameter accuracy as a function function of number of observations</em></p> <p>So what’s the bottom line? LSST is going to be a beast when it comes to discovering SLSNe, although only about 20% of the light curves will be useful on their own (assuming we know the redshift). The DFFs, in their current form, aren’t going to help us a lot compared to the WFD. If the WFD survey could (1) occasionally observe between seasons or (2) stack late-time SLSN observations, we could extend the light curves of SLSNe, which would help us extract the most science without additional followup.</p>]]></content><author><name></name></author><category term="research"/><category term="astronomy,"/><category term="research"/><summary type="html"><![CDATA[counting superluminous supernovae]]></summary></entry><entry><title type="html">detecting GW170817 with Spitzer</title><link href="https://ashleyvillar.com/al-folio/blog/2018/nsf/" rel="alternate" type="text/html" title="detecting GW170817 with Spitzer"/><published>2018-09-20T13:56:00+00:00</published><updated>2018-09-20T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2018/nsf</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2018/nsf/"><![CDATA[<p>We recently submitted a <a href="https://arxiv.org/abs/1805.08192">new paper</a> to Astrophysical Letters which presents Spitzer Space Telescope observations of GW170817 at late times.</p> <p>We downloaded publicly available Spitzer infrared data taken 43 and 74 days after the merger at 3.6 and 4.5 microns. We reduced this data using standard methods, but we found that it was incredibly difficult to remove weird galactic artifacts. This is largely due to the Spitzer’s point spread function (PSF). Spitzer has a triangular PSF, and unfortunately the spacecraft was oriented in different directions between the different observations. This made image subtraction difficult for extended objects within the image.</p> <p>Luckily, we know the position of GW170817 very well! So we were able to smooth over our subtracted image while masking out the position of GW170817. We then subtracted the smoothed version from the original version, revealing a source at the masked region. This procedure isn’t standard, so we did a lot of statistical testing to make sure we weren’t “detecting” noise or some weird pattern from the galaxy.</p> <p>[image]</p> <p>In the end, we were confident of our results, shown in the light curve below. We found that the kilonova is dimmer than our model (originally presented <a href="http://iopscience.iop.org/article/10.3847/2041-8213/aa9c84/meta">here</a>) predicts. This wasn’t super surprising, because we already knew that the late K-band data was also being over-predicted by our model.</p> <p>[image]</p> <p>The discrepancy can be due to a number of factors, but we highlighted two. First we find that the optical depth is approximately one at 40 days post-merger, meaning that the ejecta is becoming optically thin. Our model assumes that the ejecta is optically thick so that the material can be thermalized. If the kilonova enters the nebular phase, our model assumptions break down. Second, it’s possible that the thermalization efficiency we assume is incorrect. The thermalization efficiency is a function of mass, velocity and time, and the uncertainty of this function is almost an order of magnitude at late times!</p> <p>Finally, we discuss what GW170817 tells us about future missions. In (hopefully) early 2019, LIGO will turn on again for its third observing run. We expect to have improved sensitivity out to 120 Mpc for NS binary mergers. Based on GW170817, we can certainly observe future kilo novae out to similar distance with deeper observations. Looking further in the future, JWST and MIRI will be able to collect spectra and photometry of objects out to similar distances.</p>]]></content><author><name></name></author><category term="research"/><category term="astronomy,"/><category term="research"/><summary type="html"><![CDATA[a red kilonova]]></summary></entry><entry><title type="html">nsf grfp</title><link href="https://ashleyvillar.com/al-folio/blog/2018/spitzer/" rel="alternate" type="text/html" title="nsf grfp"/><published>2018-05-23T13:56:00+00:00</published><updated>2018-05-23T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2018/spitzer</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2018/spitzer/"><![CDATA[<p><em>Note: I originally posted a version of this in 2014 on another blog which I have since deleted.</em></p> <p>The National Science Foundation Graduate Research Fellowship (<a href="https://www.nsfgrfp.org/">NSF GRFP</a>) is a graduate fellowship with three years of funding. There are a ton of in-depth online resources about the application process (for example, check out these <a href="https://astrobites.org/tag/nsf/">Astrobites posts</a>), so I’m going to share just a few tips from my experience.</p> <p>One of the most useful webpages I used while applying was a <a href="http://www.alexhunterlang.com/nsf-fellowship">blog post</a> by Alex Lang. He outlines the process (with updated dates), provides links to many tips and has collected examples essays from successful applicants.</p> <p>Linked are my own essays (<a href="https://drive.google.com/file/d/0BxEq_5jCISzrMk1OOHJnNlFUb1E/view?usp=sharing">here</a> and <a href="https://drive.google.com/file/d/0BxEq_5jCISzrY1Fsb3BRazNNZ00/view?usp=sharing">here</a>), which are also available on Alex’s blog.</p> <p>I didn’t keep my reviewer feedback sheets, but my biggest critique was that I did not have a first author paper by the time I applied. That being said, you do <em>not</em> need to have published to win the NSF or to enter graduate school. As long as your show passion and creativity, you should be fine!</p> <p>Now, a few pieces of concrete advice:</p> <p>1. Start early:  I’m sure you’ve heard this many, many times by now. But it really helps! Starting early can help you get a clear idea of your research proposal and allow for many people to review your drafts. 2. Show and Tell: Or rather - tell and show. While writing your personal statement, state positive facts about yourself  (“Tell”) and immediately follow them with an example (“Show”). This is an extremely basic organizational pattern that will keep you on track throughout. 3. Bold stuff: Bold key phrases or accomplishments. The reviewers will love you. Also, don’t be afraid of using bulleted or numbered lists! 4. Have an “Accountability Buddy”: There is a lot going on fall of senior year. I had an “accountability buddy” to help me keep track of all that needed to be done. Find someone who is also applying to graduate school/fellowships (not necessarily in the same field). Help each other with essays, timelines and GRE prep. This will help you stay on track, and you get to celebrate twice when you both get into grad school!</p> <p>Good luck to everyone!</p>]]></content><author><name></name></author><category term="career"/><category term="astronomy,"/><category term="career"/><summary type="html"><![CDATA[advice for applicants]]></summary></entry><entry><title type="html">light curves</title><link href="https://ashleyvillar.com/al-folio/blog/2018/slider/" rel="alternate" type="text/html" title="light curves"/><published>2018-03-23T13:56:00+00:00</published><updated>2018-03-23T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2018/slider</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2018/slider/"><![CDATA[<p>Light curves of transients (like supernovae and kilonovae) are a powerful tool for understanding the underlying astrophysics of eruptions, explosions and collisions of stars. With a few simplifying assumptions, we can create analytical models of these events which are in good agreement with observations.</p> <h2 id="first-law-of-thermodynamics">First Law of Thermodynamics</h2> <p>To model transient light curves, we just need to use the first law of thermodynamics:</p> \[\Delta \mathsf{Energy} = \mathsf{Heat\,Added} - \mathsf{Work\,Done}\] <p>or put another way:</p> \[\frac{\Delta \mathsf{Energy}}{\Delta \mathsf{Time}} = \frac{\Delta \mathsf{Heat}}{\Delta \mathsf{Time}} - \mathsf{Pressure}\frac{\Delta \mathsf{Volume}}{\Delta \mathsf{Time}} - \mathsf{Luminosity}\] <p>The luminosity on the right-hand side of the equation can be approximated as the change in energy over a characteristic timescale of the system called the <strong>diffusion time</strong>.</p> <p>For transients, the left-hand side of the equation is powered by an internal heating source: radioactive decay, recombination, shock-heating, etc. Then, we assume that all of this energy goes into the expansion of material or electromagnetic radiation.</p> <p>If you squint your eyes, this equation looks very similar to a low-pass filter. The input energy (the left-hand side) will be stetched out over a diffusion time.</p> <p>When we solve the equation for luminosity as a function of time, we will calculate the <strong>bolometric light curve</strong> of the transient. Let’s go into more detail about each of the pieces of this equation.</p> <h2 id="input-luminosities">Input Luminosities</h2> <p>First, let’s look at a specific example of <strong>input luminosity</strong>. Supernovae are largely powered by the radioactive decay of nickel and cobalt. The input luminosity from this decay is an exponential:</p> \[L_\mathsf{inp}=M_\mathsf{Ni} (\epsilon_\mathsf{Ni} e^{-t/\tau_\mathsf{Ni}}+\epsilon_\mathsf{Co} e^{-t/\tau_\mathsf{Co}})\] <p>In this equation, \(M_\mathsf{Ni}\) is the nickel mass; \(\epsilon_\mathsf{Ni}\) and \(\epsilon_\mathsf{Co}\) are the energy generation rates of nickel and cobalt; and \(\tau_\mathsf{Ni}\) and \(\tau_\mathsf{Co}\) are the decay rates. The only free parameter that we can fit in this equation is the nickel mass, which determines the overall normalization of the light curve.</p> <p>Like I said, there are other common heating sources which power astronomical transients. All of them generally take the form of power laws or exponentials. You can find a few more (interactive!) examples at the end of this post.</p> <h2 id="diffusion-process">Diffusion Process</h2> <p>The input luminosity gets smoothed out over the diffusion timescale:</p> \[\tau_{diff}=\sqrt{\frac{2\kappa M}{\beta c v}}\] <p>In this equation, \(\kappa\) is the opacity of the ejecta material, \(M\) is the ejecta mass, \(v\) is the ejecta velocity and \(\beta\) is a geometric term. The diffusion timescale plays a huge role in the overall width of the light curve.</p> <h2 id="what-about-colors">What About Colors?</h2> <p>Everything we’ve talked about so far deals with the bolometric luminosity. In reality, we only observe a fraction of the light through a <strong>filter</strong>.</p> <p>There are two ways we counteract this issue. First, we can assume some <strong>bolometric correction</strong> in order to construct the bolometric light curves from filtered data. Our team uses an alternative approach of assuming a spectral energy distribution (SED) and directly fitting the filted light curves using <a href="http://mosfit.readthedocs.io/en/latest/">MOSFiT</a>. We typically assume a simple <strong>blackbody</strong> SED.</p> <h2 id="interactive-examples">Interactive Examples</h2> <p>The best way to learn more about these light curves is to play with them yourself!</p> <h3 id="radioactive-decay-model">Radioactive Decay Model</h3> <p>We discussed this model previously in the post. The free parameters of this model are the ejecta mass, ejecta velocity, opacity, nickel fraction and gamma-ray opacity.</p> <iframe src="http://127.0.0.1:4000/slider_java.html" width="700" height="500" frameborder="0" style="margin-left: -500"> </iframe> <p>Radioactive decay also powers kilonovae in a similar fashion. However, in the case of a kilonova, many species of elements decay simultaneous, resulting in a power law-like input luminosity function.</p> <h3 id="magnetar-spin-down">Magnetar Spin-down</h3> <p>Some bright SNe may be powered by the spin-down a millisecond pulsar with a strong magnetic field (aka a <strong>magnetar</strong>). The free parameters of this model are the ejecta mass, the ejecta velocity, the opacity, the gamma-ray opacity, the magnetic field of the magnetar and the initial spin of the magnetar. See for yourself how the magnetic field and spin can be optimized to create an extremely bright transient.</p> <iframe src="http://127.0.0.1:4000/slider_mag_java.html" width="700" height="500" frameborder="0" style="margin-left: -500"> </iframe> <h3 id="shock-interaction-with-a-circumstellar-medium">Shock Interaction with a Circumstellar Medium</h3> <p>The cooling of shocks resulting from the interaction of the supernova ejecta and surrounding circumstellar material (CSM). There are a ton of free parameters in this model, but some main ones are: the ejecta mass, the ejecta velocity, the shape of the supernova ejecta, the density of the CSM, and the radius of the CSM.</p> <iframe src="http://127.0.0.1:4000/slider_csm_java.html" width="700" height="500" frameborder="0" style="margin-left: -500"> </iframe> <h2 id="resources-and-thanks">Resources and Thanks!</h2> <p>If you want to learn more details about this model, feel free to read my recent <a href="http://iopscience.iop.org/article/10.3847/1538-4357/aa8fcb">paper</a> which goes more into the mathematics. If you found this blog post useful, you can also cite that paper and pretend you read it 0:). An older paper by <a href="http://iopscience.iop.org/article/10.1088/0004-637X/746/2/121/meta">E. Chatzopoulos</a> is also really useful and did the first census (that I know of!) of many of these anlaytical models. This very early <a href="http://articles.adsabs.harvard.edu/full/gif/1982ApJ...253..785A/0000785.000.html">paper</a> by Arnett is where most of the math comes from and is a very useful resource. Quick thanks to D. Kasen for writing these useful <a href="http://www.tapir.caltech.edu/~pmoesta/kilonova_lightcurves.pdf">notes</a> and to J. Guillochon and B. Metzger for teaching me all ‘bout light curve models.</p>]]></content><author><name></name></author><category term="guide"/><category term="astronomy,"/><category term="guide"/><summary type="html"><![CDATA[introduction to transient light curve models]]></summary></entry><entry><title type="html">intro to ML</title><link href="https://ashleyvillar.com/al-folio/blog/2018/ML/" rel="alternate" type="text/html" title="intro to ML"/><published>2018-03-14T13:56:00+00:00</published><updated>2018-03-14T13:56:00+00:00</updated><id>https://ashleyvillar.com/al-folio/blog/2018/ML</id><content type="html" xml:base="https://ashleyvillar.com/al-folio/blog/2018/ML/"><![CDATA[<p>About a month ago, I gave the first talk in a new introductory seminar series on machine learning. The talk assumes no knowledge of machine learning, and it covers the basics of data-driven models and neural networks. A link to the video is below – feel free to contact me with any questions!</p> <p><a href="https://www.youtube.com/watch?v=XIJx7Vhc3Yk" title="Machine Learning"><img src="screenshot.png" alt="Machine Lerning"/></a></p>]]></content><author><name></name></author><category term="guide"/><category term="astronomy,"/><category term="guide"/><summary type="html"><![CDATA[a short lecture on neural nets]]></summary></entry></feed>